{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1fa48a",
   "metadata": {},
   "source": [
    "# Training and Evaluation of Logistic Regression on Encrypted Data\n",
    "SOURCE: https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a41c1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a355e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 9])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 9])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_335/206129984.py:25: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data = data.drop(\"TenYearCHD\", 'columns')\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"../../../data/he_data/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    data = data.drop(\"TenYearCHD\", 'columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    # data separable by the line `y = x`\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m // 2, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# You can use whatever data you want without modification to the tutorial\n",
    "# x_train, y_train, x_test, y_test = random_data()\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e3b1a",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c76c6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c551577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0601f12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.8504331707954407\n",
      "Loss at epoch 2: 0.6863385438919067\n",
      "Loss at epoch 3: 0.6358115077018738\n",
      "Loss at epoch 4: 0.6193529367446899\n",
      "Loss at epoch 5: 0.6124349236488342\n",
      "Loss at epoch 6: 0.6089244484901428\n",
      "Loss at epoch 7: 0.6069258451461792\n",
      "Loss at epoch 8: 0.6057038903236389\n",
      "Loss at epoch 9: 0.6049202680587769\n",
      "Loss at epoch 10: 0.604399561882019\n",
      "Loss at epoch 11: 0.6040432453155518\n",
      "Loss at epoch 12: 0.6037929654121399\n",
      "Loss at epoch 13: 0.6036127209663391\n",
      "Loss at epoch 14: 0.6034800410270691\n",
      "Loss at epoch 15: 0.603380024433136\n",
      "Loss at epoch 16: 0.6033030152320862\n",
      "Loss at epoch 17: 0.6032425165176392\n",
      "Loss at epoch 18: 0.6031941175460815\n",
      "Loss at epoch 19: 0.603154718875885\n",
      "Loss at epoch 20: 0.6031221151351929\n",
      "Loss at epoch 21: 0.603094756603241\n",
      "Loss at epoch 22: 0.603071391582489\n",
      "Loss at epoch 23: 0.6030514240264893\n",
      "Loss at epoch 24: 0.6030339598655701\n",
      "Loss at epoch 25: 0.603018581867218\n",
      "Loss at epoch 26: 0.6030049324035645\n",
      "Loss at epoch 27: 0.6029927134513855\n",
      "Loss at epoch 28: 0.6029816269874573\n",
      "Loss at epoch 29: 0.602971613407135\n",
      "Loss at epoch 30: 0.6029624938964844\n",
      "Loss at epoch 31: 0.6029541492462158\n",
      "Loss at epoch 32: 0.6029463410377502\n",
      "Loss at epoch 33: 0.6029390692710876\n",
      "Loss at epoch 34: 0.6029324531555176\n",
      "Loss at epoch 35: 0.6029260754585266\n",
      "Loss at epoch 36: 0.6029201745986938\n",
      "Loss at epoch 37: 0.6029146313667297\n",
      "Loss at epoch 38: 0.6029094457626343\n",
      "Loss at epoch 39: 0.6029044389724731\n",
      "Loss at epoch 40: 0.6028997898101807\n",
      "Loss at epoch 41: 0.6028953194618225\n",
      "Loss at epoch 42: 0.6028910875320435\n",
      "Loss at epoch 43: 0.6028870344161987\n",
      "Loss at epoch 44: 0.6028831601142883\n",
      "Loss at epoch 45: 0.602879524230957\n",
      "Loss at epoch 46: 0.6028759479522705\n",
      "Loss at epoch 47: 0.6028725504875183\n",
      "Loss at epoch 48: 0.6028693318367004\n",
      "Loss at epoch 49: 0.6028661727905273\n",
      "Loss at epoch 50: 0.6028631925582886\n"
     ]
    }
   ],
   "source": [
    "# define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 50\n",
    "\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88dd18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.703592836856842\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e8bea",
   "metadata": {},
   "source": [
    "## Encrypted Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a77c1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        # TenSEAL processes lists and not torch tensors,\n",
    "        # so we take out the parameters from the PyTorch model\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        # We don't need to perform sigmoid as this model\n",
    "        # will only be used for evaluation, and the label\n",
    "        # can be deduced without applying sigmoid\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "        \n",
    "    ################################################\n",
    "    ## You can use the functions below to perform ##\n",
    "    ## the evaluation with an encrypted model     ##\n",
    "    ################################################\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "\n",
    "eelr = EncryptedLR(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050d9e4",
   "metadata": {},
   "source": [
    "### Create TenSEAL contex \n",
    "for specifying the scheme and parameters we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d8fa6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb8078fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7aa3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test_set of 334 entries in 2 seconds\n",
      "Accuracy: 231/334 = 0.6916167664670658\n",
      "Difference between plain and encrypted accuracies: 0.011976063251495361\n"
     ]
    }
   ],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparaison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "    \n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97375c90",
   "metadata": {},
   "source": [
    "## Training an Encrypted Logistic Regression Model on Encrypted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "552dc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # we accumulate gradients and counts the number of iterations\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9720c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd986bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 15 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73609a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on plain data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on encrypted data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    fig = plt.plot(x, y)\n",
    "    \n",
    "# plain distribution\n",
    "lr = LR(n_features)\n",
    "data = lr.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "print(\"Distribution on plain data:\")\n",
    "plt.show()\n",
    "\n",
    "# encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    print(\"Distribution on encrypted data:\")\n",
    "    plt.show()\n",
    "\n",
    "eelr = EncryptedLR(lr)\n",
    "eelr.encrypt(ctx_training)\n",
    "encrypted_out_distribution(eelr, enc_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afc54f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.37425148487091064\n",
      "Accuracy at epoch #1 is 0.667664647102356\n",
      "Accuracy at epoch #2 is 0.6616766452789307\n",
      "Accuracy at epoch #3 is 0.6766467094421387\n",
      "Accuracy at epoch #4 is 0.71257483959198\n",
      "Accuracy at epoch #5 is 0.6796407103538513\n",
      "Accuracy at epoch #6 is 0.703592836856842\n",
      "Accuracy at epoch #7 is 0.6706587076187134\n",
      "Accuracy at epoch #8 is 0.697604775428772\n",
      "Accuracy at epoch #9 is 0.673652708530426\n",
      "Accuracy at epoch #10 is 0.682634711265564\n",
      "Accuracy at epoch #11 is 0.682634711265564\n",
      "Accuracy at epoch #12 is 0.6856287717819214\n",
      "Accuracy at epoch #13 is 0.682634711265564\n",
      "Accuracy at epoch #14 is 0.688622772693634\n",
      "Accuracy at epoch #15 is 0.682634711265564\n",
      "Accuracy at epoch #16 is 0.6916167736053467\n",
      "Accuracy at epoch #17 is 0.688622772693634\n",
      "Accuracy at epoch #18 is 0.688622772693634\n",
      "Accuracy at epoch #19 is 0.688622772693634\n",
      "Accuracy at epoch #20 is 0.6916167736053467\n",
      "Accuracy at epoch #21 is 0.6916167736053467\n",
      "Accuracy at epoch #22 is 0.6946107745170593\n",
      "Accuracy at epoch #23 is 0.6916167736053467\n",
      "Accuracy at epoch #24 is 0.697604775428772\n",
      "Accuracy at epoch #25 is 0.6916167736053467\n",
      "Accuracy at epoch #26 is 0.703592836856842\n",
      "Accuracy at epoch #27 is 0.6946107745170593\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_335/3018300670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meelr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0meelr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0meelr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_335/1189098362.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncryptedLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.8/site-packages/tenseal/tensors/ckksvector.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"CKKSVector\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdot_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"CKKSVector\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eelr = EncryptedLR(LR(n_features))\n",
    "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    eelr.encrypt(ctx_training)\n",
    "    \n",
    "    # if you want to keep an eye on the distribution to make sure\n",
    "    # the function approxiamation is still working fine\n",
    "    # WARNING: this operation is time consuming\n",
    "    # encrypted_out_distribution(eelr, enc_x_train)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        enc_out = eelr.forward(enc_x)\n",
    "        eelr.backward(enc_x, enc_out, enc_y)\n",
    "    eelr.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    \n",
    "    eelr.decrypt()\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(f\"Final accuracy is {accuracy}\")\n",
    "\n",
    "diff_accuracy = plain_accuracy - accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
