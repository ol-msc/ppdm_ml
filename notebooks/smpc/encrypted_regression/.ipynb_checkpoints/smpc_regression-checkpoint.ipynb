{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9842fc8e",
   "metadata": {},
   "source": [
    "# Encrypted Inference-Linear Regression with Syft and SMPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22860954",
   "metadata": {},
   "source": [
    "Encrypted Inference is the process of performing inference with machine learning models such\n",
    "that model owner cannot observe the true input data nor can the data owner see the true model weights.\n",
    "The weights and data are encrypted by splitting them into shares and performiming computations\n",
    "according to a protocol. The general class of methods know as Secure Multi Party Computation (SMPC).\n",
    "\n",
    "This case study contains a scenario of successful encrypted inference with encrypted ML model (linear regression)\n",
    "on an encrypted data.\n",
    "This experiment is implemented with the Torch, Syft and SyMPC frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3b6e4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#External libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#Import torch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#Import syft\n",
    "import syft as sy\n",
    "sy.logger.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2776bce",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "Initial data loading, normalization and splitting into train and test\n",
    "parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset and add headers\n",
    "dataset=pd.read_csv(\"../../../data/housing_data/housing.data\",delim_whitespace=True,\n",
    "                    names=[\"crim\",\"zn\",\"indus\",\n",
    "                           \"chas\",\"nox\",\"rm\",\n",
    "                           \"age\",\"dis\",\"rad\",\n",
    "                           \"tax\",\"ptratio\",\"black\",\n",
    "                           \"lstat\",\"medv\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5b17d58",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Relevant Information: Concerns housing values in suburbs of Boston.\n",
    "Number of Instances: 506\n",
    "Number of Attributes: 13 continuous attributes (including \"class\"\n",
    "                         attribute \"MEDV\"), 1 binary-valued attribute.\n",
    "Attribute Information:\n",
    "| idx | Attribute | Description                                                           |\n",
    "|-----|-----------|-----------------------------------------------------------------------|\n",
    "| 1   | CRIM      | per capita crime rate by town                                         |\n",
    "| 2   | ZN        | proportion of residential land zoned for lots over 25,000 sq.ft.      |\n",
    "| 3   | INDUS     | proportion of non-retail business acres per town                      |\n",
    "| 4   | CHAS      | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| 5   | NOX       | nitric oxides concentration (parts per 10 million)                    |\n",
    "| 6   | RM        | average number of rooms per dwelling                                  |\n",
    "| 7   | AGE       | proportion of owner-occupied units built prior to 1940                |\n",
    "| 8   | DIS       | weighted distances to five Boston employment centres                  |\n",
    "| 9   | RAD       | index of accessibility to radial highways                             |\n",
    "| 10  | TAX       | full-value property-tax rate per 10,000 dollars                       |\n",
    "| 11  | PTRATIO   | pupil-teacher ratio by town                                           |\n",
    "| 12  | B         | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        |\n",
    "| 13  | LSTAT     | \\% lower status of the population                                     |\n",
    "| 14  | MEDV      | Median value of owner-occupied homes in 1000's dollars                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize and look at columns and rows of dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into features and target variables\n",
    "features = dataset.drop(\"medv\",axis=1)\n",
    "targets = dataset[\"medv\"]\n",
    "\n",
    "#Normalize features\n",
    "features = features.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "#display dataset\n",
    "display(features)\n",
    "display(targets)\n",
    "\n",
    "\n",
    "#Convert features and targets into torch tensors\n",
    "features = torch.tensor(features.values.astype(np.float32))\n",
    "targets = torch.tensor(targets.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 16\n",
    "epochs = 300\n",
    "train_test_split = 0.8\n",
    "lr = 0.001\n",
    "\n",
    "#split data to train and test\n",
    "train_indices=int(len(features)*train_test_split)\n",
    "\n",
    "train_x = features[:train_indices]\n",
    "train_y = targets[:train_indices]\n",
    "\n",
    "test_x = features[train_indices+1:]\n",
    "test_y = targets[train_indices+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d917918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, y):\n",
    "    batches = []\n",
    "    for index in range(0,len(train_x)+1,batch_size):\n",
    "        batches.append((X[index:index+batch_size],y[index:index+batch_size]))\n",
    "    \n",
    "    return batches\n",
    "train_batches = get_batches(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc5809",
   "metadata": {},
   "source": [
    "### Plaintext training\n",
    "This part contains linear model definition, training cycle and model evaluation in regular, non-encrypted environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3506a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Linear regression model\n",
    "class LinearSyNet(sy.Module): # to make model accessable within SMPC session the special wrapper must be used\n",
    "    def __init__(self, torch_ref):\n",
    "        super(LinearSyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(13,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model, loss function and optimizer\n",
    "model = LinearSyNet(torch)\n",
    "criterion = torch.nn.MSELoss(reduction='mean') \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca131bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  for index in range(0,len(train_batches)):\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(train_batches[index][0]).reshape([-1])\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs,train_batches[index][1])\n",
    "    running_loss += loss\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "  test_accuracy = criterion(model(test_x).reshape([-1]),test_y)\n",
    "  if((epoch%50)==0):\n",
    "     print(f\"Epoch {epoch}/{epochs}  Running Loss : {running_loss.item()/batch_size} and test loss: {test_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10599c01",
   "metadata": {},
   "source": [
    "### Plaintext Inference\n",
    "This part contains performing regular, plaintext inference for result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform inference in plaintext\n",
    "start_time=time.time()\n",
    "plaintext_predictions = model(test_x).reshape([-1])\n",
    "end_time=time.time()\n",
    "#Calculate inference time and MSELoss\n",
    "print(\"MSE Loss: \",criterion(plaintext_predictions,test_y).item())\n",
    "print(\"Inference time: \",str(end_time-start_time),\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92024d",
   "metadata": {},
   "source": [
    "### Encrypted Inference\n",
    "This part contains the steps for performing encrypted inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfe6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SyMPC imports required for encrypted inference\n",
    "import sympc\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.protocol import FSS,Falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that generates required number of syft clients and return them.\n",
    "def get_clients(n_parties):\n",
    "  parties=[]\n",
    "  for index in range(n_parties): \n",
    "      parties.append(sy.VirtualMachine(name = \"worker\"+str(index)).get_root_client())\n",
    "  return parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to split and share the data between simulate parties\n",
    "def split_send(data,session):\n",
    "    \"\"\"Splits data into number of chunks equal to number of parties and distributes it to respective parties.\"\"\"\n",
    "    data_pointers = []\n",
    "    split_size = int(len(data)/len(session.parties))+1\n",
    "    for index in range(0,len(session.parties)):\n",
    "        ptr=data[index*split_size:index*split_size+split_size].share(session=session)\n",
    "        data_pointers.append(ptr)\n",
    "    return data_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b304f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform encrypted inference\n",
    "def inference(n_clients,protocol=None):\n",
    "  # Get VM clients \n",
    "  parties=get_clients(n_clients)\n",
    "  # Setup the session for the computation\n",
    "  if(protocol):\n",
    "     session = Session(parties = parties,protocol = protocol)\n",
    "  else:\n",
    "     session = Session(parties = parties)\n",
    "  SessionManager.setup_mpc(session)\n",
    "  #Split data and send data to clients\n",
    "  pointers = split_send(test_x,session)\n",
    "  #Encrypt model \n",
    "  mpc_model = model.share(session)\n",
    "  #Perform inference and measure time taken\n",
    "  start_time = time.time()\n",
    "  results = []\n",
    "  for ptr in pointers:\n",
    "     encrypted_results = mpc_model(ptr)\n",
    "     plaintext_results = encrypted_results.reconstruct()\n",
    "     results.append(plaintext_results)\n",
    "  end_time = time.time()\n",
    "  print(f\"Time for inference: {end_time-start_time}s\")\n",
    "  predictions = torch.cat(results).reshape([-1])\n",
    "  #Calculate Loss\n",
    "  print(\"MSE Loss: \",criterion(predictions,test_y).item())\n",
    "    \n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=inference(3, Falcon(\"semi-honest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare first 100 encrypted inference results\n",
    "for index in range(0,101):\n",
    "    print(f\"Index {index}\")\n",
    "    print(f\"Encrypted Prediction Output {predictions[index].item()}\")\n",
    "    print(f\"Plaintext Prediction Output {plaintext_predictions[index].item()}\")\n",
    "    print(f\"Expected Prediction: {test_y[index]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=inference(3,Falcon(\"malicious\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a68f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Inference with 3 parties')\n",
    "predictions=inference(3)\n",
    "print()\n",
    "print('Inference with 5 parties')\n",
    "predictions=inference(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d1bfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summary\n",
    "This case study contains the scenario of performing the inference on encrypted data using the\n",
    "encrypted model. The inference process is implemented using the SyMPC, Syft and Torch.\n",
    "The inference was performed several time using different protocols, adversary models and number of parties.\n",
    "The plain and encrypted inferences results are very close to each other, difference in fifth place after the point\n",
    "is considered as acceptable.\n",
    "Summarizing all statements and performed action the experiment is considered as successful, the\n",
    "privacy of data was preserved without significant precision loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
