{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Brain Tumor Detection with SyMPC\n",
    "### Oleksandr Lytvyn\n",
    "This case study is a logical continuation of the previous experiment with encrypted linear regression inference.\n",
    "Here the scenario of encrypted image classification using an encrypted model is presented.\n",
    "The purpose of the experiment to examine compatibility the SMPC and Deep Learning approaches.\n",
    "The main tools for scenario implementation are Torch, Syft and SyMPC.\n",
    "\n",
    "Scenario consist of data preparation, model creation and training, plaintext inference,\n",
    "simulation of multiple parties and encrypted inference.\n",
    "\n",
    "The classification is made on publicly-available dataset containing images for\n",
    "brain tumor detection.\n",
    "dataset: [kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import syft as sy\n",
    "import time\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom BrainMRIDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "class BrainMRIDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data_dir,reshape=True,height=128,width=128, transform=None):\n",
    "        self.dataDirectory = data_dir\n",
    "        self.no_class = glob(data_dir+'/no/*')\n",
    "        self.yes_class = glob(data_dir+'/yes/*')\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.reshape=reshape\n",
    "        self.transform = transform\n",
    "\n",
    "        labels = [0 for i in range(len(self.no_class))]\n",
    "        labels += [1 for i in range(len(self.yes_class))]\n",
    "\n",
    "        image_links = self.no_class + self.yes_class\n",
    "        self.dataframe = pd.DataFrame({\n",
    "            'image':image_links,\n",
    "            'labels': labels\n",
    "        })\n",
    "\n",
    "        self.dataframe = shuffle(self.dataframe)\n",
    "        self.dataframe.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.no_class)+len(self.yes_class)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        image = self.dataframe['image'][idx]\n",
    "        label = self.dataframe['labels'][idx]\n",
    "\n",
    "        image = Image.open(image).convert(\"L\")\n",
    "\n",
    "        if self.reshape:\n",
    "            image = image.resize((self.height,self.width))\n",
    "\n",
    "        array = np.asarray(image)\n",
    "        if self.transform:\n",
    "            array = self.transform(array)\n",
    "        \n",
    "        array = array.reshape(1, self.height,self.width)\n",
    "        image = torch.tensor(array)\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return [image,label]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.dataframe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining data transformation for further augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.ColorJitter(brightness=0.4),\n",
    "        transforms.ColorJitter(brightness=0.5),\n",
    "        transforms.ColorJitter(brightness=0.6),\n",
    "        transforms.ColorJitter(brightness=0.7)\n",
    "    ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "rotation_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomRotation(degrees=30),\n",
    "        transforms.RandomRotation(degrees=25),\n",
    "        transforms.RandomRotation(degrees=20),\n",
    "        transforms.RandomRotation(degrees=15)\n",
    "    ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "flip_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomHorizontalFlip(p=1),\n",
    "        transforms.RandomVerticalFlip(p=1),\n",
    "        transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.RandomVerticalFlip(p=1)\n",
    "        ])\n",
    "    ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "grayscale_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.RandomPerspective(distortion_scale=.1, p=1)\n",
    "    ]),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and augument dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#upload data\n",
    "path_to_project_root = '../../../'\n",
    "data_dir = path_to_project_root + 'data/brain_tumor_imgs'\n",
    "dataset = BrainMRIDataset(data_dir, height=64, width=64, transform=None) + \\\n",
    "          BrainMRIDataset(data_dir, height=64, width=64, transform=rotation_transformations) + \\\n",
    "          BrainMRIDataset(data_dir, height=64, width=64, transform=flip_transformations) + \\\n",
    "          BrainMRIDataset(data_dir, height=64, width=64, transform=grayscale_transformations) + \\\n",
    "          BrainMRIDataset(data_dir, height=64, width=64, transform=color_transformations)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data to the train and test suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasetsize = len(dataset)\n",
    "train_size = int(datasetsize * 0.8)\n",
    "whole_test_size = datasetsize - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, whole_test_size])\n",
    "\n",
    "print(f\"Whole dataset size: {datasetsize}\\n\"\n",
    "      f\"Train dataset size: {train_size}\\n\"\n",
    "      f\"Whole test size: {whole_test_size}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualize data\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(20):\n",
    "    target = train_data[i][1]\n",
    "    plt.subplot(4,5, i+1)\n",
    "    plt.imshow(train_data[i][0][0])\n",
    "    plt.title(f'Actual: {target}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### MODEL with Syft wrapper\n",
    "This part contains definition of CNN model using the Syft wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BrainTumorModel(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(BrainTumorModel, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 128, kernel_size=3)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(128,32,kernel_size=2)\n",
    "        self.linear1 = self.torch_ref.nn.Linear(30,64)\n",
    "        self.linear2 = self.torch_ref.nn.Linear(64,32)\n",
    "        self.flat = self.torch_ref.nn.Flatten(1)\n",
    "        self.linear3 = self.torch_ref.nn.Linear(30720,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create several model + hyperparameters sets\n",
    "By doing this the different model could be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single model usage\n",
    "# model = BrainTumorModel(torch_ref=torch)\n",
    "# print(model)\n",
    "models_and_params = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    models_and_params.append({\n",
    "        \"model\": BrainTumorModel(torch_ref=torch),\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"epochs\": 100*(i*2)\n",
    "    })\n",
    "\n",
    "print(models_and_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Test and Train cylce functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for single model usage\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# num_epochs = 800\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def test(model, test_loader, loss_fn):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    number_of_imags = len(test_loader)\n",
    "    for image, label in test_loader:\n",
    "        pred = model.forward(image.float())\n",
    "        test_loss += loss_fn(pred, label).item()\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        equality = (label.data == pred)\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return test_loss/number_of_imags, accuracy/number_of_imags\n",
    "\n",
    "\n",
    "def train(model, train_data, test_data, optimizer, num_epochs = 100, batch_size = 32,):\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        i=0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            image, label = batch\n",
    "            images_batch = Variable(image)\n",
    "            labels_batch = Variable(label)\n",
    "            output = model(images_batch.float())\n",
    "            loss = loss_fn(output, labels_batch)\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i+=1\n",
    "            break\n",
    "        if epoch%10 == 0:\n",
    "            model.eval()\n",
    "            test_loss, accuracy = test(model, test_loader, loss_fn)\n",
    "            print(f'Epochs: {epoch} Loss: {total_loss/i: .4f}, Accuracy: {accuracy: .4f}')\n",
    "            model.train()\n",
    "        loss_list.append(total_loss/batch_size)\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple model training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model_and_params in enumerate(models_and_params):\n",
    "    # get attributes\n",
    "    model = model_and_params[\"model\"] \n",
    "    epochs = model_and_params[\"epochs\"]\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_and_params[\"learning_rate\"])\n",
    "    print(f\"---------------------------------------\")\n",
    "    print(f\"Started model {idx} for {epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    # train model\n",
    "    loss_list_dumb = train(model, train_data, test_data,optimizer, num_epochs=epochs)\n",
    "    model_and_params[\"loss_list\"] = [loss_item.detach() for loss_item in loss_list_dumb]\n",
    "    \n",
    "    \n",
    "    print(f\"Finished model {idx} for {epochs} epochs, for {time.time() - start_time}\")\n",
    "    print(f\"---------------------------------------\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation + Loss Plot\n",
    "This part contains models loss plots and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,20))\n",
    "fig, axs = plt.subplots(10, figsize=(20,40))\n",
    "\n",
    "for x in range(0,10):\n",
    "    first_model_and_params = models_and_params[x]\n",
    "    axs[x].plot(list(range(first_model_and_params[\"epochs\"])), first_model_and_params[\"loss_list\"])\n",
    "    axs[x].set_title(f\"Model {x} Loss v/s Epochs ({first_model_and_params['epochs']} epochs)\")\n",
    "    \n",
    "\n",
    "plt.figure\n",
    "plt.show()\n",
    "\n",
    "# for single model usage\n",
    "# loss_list = train(model, train_data, test_data, num_epochs=num_epochs)\n",
    "# loss_list = [loss_item.detach() for loss_item in loss_list]\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# plt.plot(list(range(num_epochs)),loss_list)\n",
    "# plt.title(\"Loss v/s Epochs\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate trained models\n",
    "for idx, model_and_params in enumerate(models_and_params):\n",
    "    print(f\"Evaluating model {idx}\")\n",
    "    model = model_and_params[\"model\"]\n",
    "    model.eval()\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "    test_loss, accuracy, = test(model, test_loader, loss_fn)\n",
    "    print(f'Test Accuracy: {accuracy:.4f} |'\n",
    "          f'Test Loss: {test_loss:.4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosing the 8th model as the main one\n",
    "model = models_and_params[8][\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing predictions in non-encrypted environment\n",
    "This part contains visualization of first 20 predictions in non-encrypted environment using the best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loader = DataLoader(test_data, batch_size=1)\n",
    "\n",
    "mapping = {0:'no',1:'yes'}\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "i = 0\n",
    "correct = 0\n",
    "raw_predictions = []\n",
    "for img, lbl in plot_loader:\n",
    "    if i == 20: break\n",
    "    pred = model(img.float())\n",
    "    pred = torch.argmax(pred,dim=1)\n",
    "    raw_predictions.append(pred)\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(img[0][0].cpu())\n",
    "    if lbl == pred: correct += 1\n",
    "    plt.title(f'Actual: {mapping[lbl.cpu().detach().item()]} Predicted: {mapping[pred.cpu().detach().item()]}')\n",
    "    i+=1\n",
    "plt.show()\n",
    "print(f\"actual accuracy: {correct/i: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encrypted Inference\n",
    "This part contains implementation fo encrypted inference using the SyMPC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#SyMPC imports required for encrypted inference\n",
    "import sympc\n",
    "from sympc.session import Session\n",
    "from sympc.session import SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "from sympc.protocol import FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define function that generates required number of syft clients and return them.\n",
    "def get_clients(n_parties):\n",
    "  parties=[]\n",
    "  for index in range(n_parties):\n",
    "      parties.append(sy.VirtualMachine(name = \"worker\"+str(index)).get_root_client())\n",
    "\n",
    "  return parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating parties and session\n",
    "parties = get_clients(2)\n",
    "session = Session(parties=parties)\n",
    "SessionManager.setup_mpc(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypting and splitting data between simulated participants\n",
    "ptrs = []\n",
    "labels = []\n",
    "for i, (img, lbl) in enumerate(plot_loader):\n",
    "    if i == 20: break\n",
    "    img_f = img.type(torch.float32)\n",
    "    ptrs.append(MPCTensor(secret=img_f,session=session, requires_grad=True))\n",
    "    labels.append(lbl)   \n",
    "len(ptrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Encrypting and sharing model within the session\n",
    "mpc_model = model.share(session)\n",
    "mpc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Encrypted Inference\n",
    "This part contains the encrypted inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "results = []\n",
    "\n",
    "for ptr in ptrs:\n",
    "    encrypted_results = mpc_model(ptr)\n",
    "    print(f\"encrypted results: {encrypted_results}\")\n",
    "    plaintext_results = encrypted_results.reconstruct()\n",
    "    print(f\"plain text results: {plaintext_results}\")\n",
    "    results.append(plaintext_results)\n",
    "\n",
    "end_time = time.time()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Encrypted Inference Results\n",
    "This part contains visualization of encrypted inference results together with\n",
    "several metrics to compare encrypted and non-encrypted inference predictions success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "iter_loader = iter(plot_loader)\n",
    "succes_sympc_overal = 0\n",
    "succes_sympc_raw = 0\n",
    "for i in range(20):\n",
    "    img, label = next(iter_loader)\n",
    "    pred = results[i]\n",
    "    raw_pred = raw_predictions[i]\n",
    "    target = labels[i]\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(img[0][0])\n",
    "    plt.title(f\"A: {mapping[target.detach().item()]} | \" +\n",
    "              f\"sympc: {mapping[pred.detach().item()]} | \" +\n",
    "              f\"raw: {mapping[raw_pred.detach().item()]}\")\n",
    "    if pred == label: succes_sympc_overal += 1\n",
    "    if pred == raw_pred: succes_sympc_raw += 1\n",
    "    \n",
    "plt.show()\n",
    "print(f\"Time for inference: {end_time - start_time}\")\n",
    "print(f\"Succes rate (sympc pred/actual labels): {succes_sympc_overal/i: .2f}\")\n",
    "print(f\"Succes rate (sympc pred/raw pred): {succes_sympc_raw/i: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Summary\n",
    "This case study contains the scenario of performing encrypted image classification.\n",
    "The scenario uses SMPC paradigm to implement the secure computation process.\n",
    "During the scenario the CNN model is trained in regular environment,\n",
    "several parties simulate, data encrypted and shared within parties,\n",
    "model encrypted and shared within session, encrypted image classification\n",
    "is performed and results are visualized.\n",
    "\n",
    "The accuracy of predictions in SMPC environment was reduced because high\n",
    "number of operation performed within the CNN model (this is a specific of FSS the protocol).\n",
    "However, the model still showed the considerable accuracy of predictions.\n",
    "Since the computation is performed jointly in an encrypted form the privacy of\n",
    "individual data records (images) is preserved.\n",
    "\n",
    "Summarizing all performed actions and statements the experiment is considered as successful.\n",
    "The experiment proves the possibility of combining the SMPC and Deep Learning approaches,\n",
    "and serves as a base for the further research and implementation of other scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}