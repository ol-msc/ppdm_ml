{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ENCRYPTED INFERENCE USING RESNET-18\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1) # We ask torch to use a single thread\n",
    "# as we run async code which conflicts with multithreading\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# data_dir = os.path.realpath('../../data/hymenoptera_data')\n",
    "data_dir = '../../data/hymenoptera_data'\n",
    "image_dataset = datasets.ImageFolder(data_dir+'/val', data_transform)\n",
    "dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_size = len(image_dataset)\n",
    "class_names = image_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "state = torch.load(\"../../models/resnet18_ants_bees.pt\", map_location='cpu')\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "model.maxpool, model.relu = model.relu, model.maxpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "data_owner = sy.VirtualWorker(hook, id=\"data_owner\")\n",
    "model_owner = sy.VirtualWorker(hook, id=\"model_owner\")\n",
    "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove compression to have faster communication, because compression time \n",
    "# is non-negligible: we send to workers crypto material which is very heavy\n",
    "# and pseudo-random, so compressing it takes a long time and isn't useful:\n",
    "# randomness can't be compressed, otherwise it wouldn't be random!\n",
    "from syft.serde.compression import NO_COMPRESSION\n",
    "sy.serde.compression.default_compress_scheme = NO_COMPRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding data to the **data_owner** and the model on **model_owner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data, true_labels = next(iter(dataloader))\n",
    "data_ptr = data.send(data_owner)\n",
    "\n",
    "true_predicition = model(data)\n",
    "model_ptr = model.send(model_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encryption_kwargs = dict(\n",
    "    workers=(data_owner, model_owner), # the workers holding shares of the secret-shared encrypted data\n",
    "    crypto_provider=crypto_provider, # a third party providing some cryptography primitives\n",
    "    protocol=\"fss\", # the name of the crypto protocol, fss stands for \"Function Secret Sharing\"\n",
    "    precision_fractional=4, # the encoding fixed precision (i.e. floats are truncated to the 4th decimal)\n",
    ")\n",
    "\n",
    "encrypted_data = data_ptr.encrypt(**encryption_kwargs).get()\n",
    "encrypted_model = model_ptr.encrypt(**encryption_kwargs).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       "\t-> [PointerTensor | me:82059159364 -> data_owner:12074529607]\n",
       "\t-> [PointerTensor | me:31469196163 -> model_owner:81424253850]\n",
       "\t*crypto provider: crypto_provider*"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secure inference\n",
    "We are now able to run our secure inference, so let's do it and let's compare it to the true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py:122: UserWarning: Use dtype instead of field\n",
      "  warnings.warn(\"Use dtype instead of field\")\n",
      "Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/pool.py\", line 513, in _handle_workers\n",
      "    cls._maintain_pool(ctx, Process, processes, pool, inqueue,\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/pool.py\", line 337, in _maintain_pool\n",
      "    Pool._repopulate_pool_static(ctx, Process, processes, pool,\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/lytvyn/anaconda3/envs/syft_python/lib/python3.8/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "encrypted_predictions = encrypted_model(encrypted_data)\n",
    "encrypted_labels = encrypted_prediction.argmax(dim=1)\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")\n",
    "\n",
    "labels = encrypted_labels.decrypt()\n",
    "\n",
    "print(\"Predicted labels:\", labels)\n",
    "print(\"     True labels:\", true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
